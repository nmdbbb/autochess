# Model Configuration
model:
  type: transformer
  d_model: 256
  nhead: 8
  num_layers: 6
  dim_feedforward: 1024
  dropout: 0.1

# Training Configuration
training:
  num_iterations: 1000
  num_games_per_iteration: 100
  batch_size: 512
  learning_rate: 0.0005
  weight_decay: 1e-4
  gradient_clip: 1.0
  epochs: 100

# MCTS Configuration
mcts:
  simulations: 400
  cpuct: 1.5
  dirichlet_alpha: 0.3
  dirichlet_epsilon: 0.25

# Self-Play Configuration
self_play:
  games_per_iteration: 100
  temperature: 1.0
  temperature_decay: 0.99
  max_moves: 512
  replay_buffer_size: 10000

# Distributed Training
distributed:
  num_workers: 4
  ray:
    redis_address: "localhost:6379"
    redis_password: ""
    object_store_memory: 1000000000
    num_cpus: 8
    num_gpus: 1

# Evaluation
evaluation:
  num_games: 20
  stockfish_depth: 10
  stockfish_time: 1.0
  evaluation_interval: 5

# Checkpointing
checkpoint:
  save_interval: 10
  max_to_keep: 5
  checkpoint_dir: "checkpoints"

# Logging
logging:
  tensorboard_dir: "runs"
  log_interval: 100
  metrics:
    - "policy_loss"
    - "value_loss"
    - "replay_buffer_size"
    - "win_rate"
    - "elo_rating" 